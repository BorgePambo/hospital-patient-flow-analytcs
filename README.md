# Real-Time Patient Flow Analytics on Azure

ðŸ“Œ Project Overview
Este projeto demonstra um #pipeline de engenharia de dados em tempo real para a Ã¡rea da saÃºde, projetado para analisar o fluxo de pacientes entre os departamentos de um hospital utilizando serviÃ§os da nuvem Azure.
O pipeline ingere dados em streaming, processa-os no Databricks (PySpark) e os armazena no Azure Synapse SQL Pool para anÃ¡lise e visualizaÃ§Ã£o.

###### Parte 1 â€“ Engenharia de Dados: Construir o pipeline de ingestÃ£o e transformaÃ§Ã£o em tempo real.
###### Parte 2 â€“ AnÃ¡lises: Conectar o Synapse ao Power BI e criar um dashboard interativo com KPIs hospitalares.

PIPELINE DESIGN
<img width="1071" height="610" alt="pipeline_hospi" src="https://github.com/user-attachments/assets/9f83f05a-4cb8-4017-ad74-7771f4901be2" />

# OBJETIVO
    1 - Coletar dados de pacientes em tempo real via Azure Event Hub.
    
    2 - Processar e limpar os dados usando Databricks (camadas Bronze â†’ Silver â†’ Gold).
    
    3 - Implementar um esquema estrela no Synapse SQL Pool para consultas eficientes.
    
    4 - Habilitar Controle de VersÃ£o com Git.

# Project Structure
    real-time-patient-flow-azure/
    â”‚
    â”œâ”€â”€ databricks-notebooks/  # Transformation notebooks
    â”‚   â”œâ”€â”€ 01_bronze_rawdata.py
    â”‚   â”œâ”€â”€ 02_silver_cleandata.py
    â”‚   â””â”€â”€ 03_gold_transform.py
    â”œâ”€â”€ simulator/             # Data simulation scripts
    â”‚   â””â”€â”€ patient_flow_generator.py
    â”œâ”€â”€ sqlpool-quries/        # SQL scripts for Synapse
    â”‚   â””â”€â”€ SQL_pool_quries.sql
    â”œâ”€â”€ git_commands/                  # Git Commands
    â””â”€â”€ README.md              # Project documentation

# Arquitetura de Dados
    O pipeline usa uma arquitetura em mÃºltiplas camadas:
    
     **Bronze**: Dados brutos em JSON vindos do Event Hub armazenados no ADLS.  
     **Silver**: Dados limpos e estruturados (tipos validados e tratamento de nulos).   
     **Gold**: Dados agregados e prontos para consumo em BI.

# Tools & Technologies: 
    Azure Event Hub â€“ IngestÃ£o de dados em tempo real
    Azure Databricks â€“ Processamento ETL usando PySpark.
    Azure Data Lake Storage â€“ Armazenamento de dados brutos e dados tratados
    Azure Synapse SQL Pool â€“ Data warehouse para anÃ¡lise 
    Power BI â€“ VisualizaÃ§Ã£o
    Python 3.9+ â€“ Core programming
    Git â€“ Version control

# Design de Star Schema

A camada Gold no Synapse usa um esquema em estrela para anÃ¡lises rÃ¡pidas:
Tabela Fato: FactPatientFlow â€” contÃ©m visitas dos pacientes, tempos de espera, entrada/saÃ­da.
Tabelas DimensÃ£o:
        DimDepartment: informaÃ§Ãµes dos departamentos.
        DimPatient: dados demogrÃ¡ficos dos pacientes.
        DimTime: dimensÃ£o de datas e horÃ¡rios.


# ImplementaÃ§Ã£o passo a passo
##### 1. ConfiguraÃ§Ã£o do Event Hub
Criado o namespace do Event Hub e o hub patient-flow.
Configurados os grupos de consumidores para o streaming no Databricks.

#### 2. SimulaÃ§Ã£o de Dados
Desenvolvido o script Python patient_flow_generator.py para enviar dados falsos de pacientes (departamentos, tempo de espera, status de alta) para o Event Hub.
Inclui o cÃ³digo do produtor (producer).

#### 3. ConfiguraÃ§Ã£o do Storage
Configurado o Azure Data Lake Storage (ADLS Gen2).

#### 4. Notebooks: https://github.com/BorgePambo/hospital-patient-flow-analytcs/blob/main/databricks-notebook/01-bronze_raw_data.ipynb




